Final Project Documentation:
First, a bit of background: This project was implemented on an ubuntu image in a docker container. As a result, this howto and all following instructions will be for an ubuntu image and should work or be similar for other linux distributions. 

Prerequisites:
This howto assumes that you have both Python 2.7 and Python 3.5 installed, and that you are working within either an ubuntu distribution or an ubuntu container with Docker or similar software
[Optional]: If you want to display/read the xml files produced by this software, you will need software that can read those files installed: Sibelius, Finale, MuseScore, etc. 

Installing Python-OpenCV
**Note: While installing OpenCV 3 was a possibility, there was less support for the newer version and at times, it was impossible to use. As a result, I made the decision to use OpenCV 2, which requires Python 2, despite the fact that the machine learning aspect of this uses Python 3 to run. Using the previous version of OpenCV gave me more resources to learn the syntactical side of things while also learning about computer vision techniques in general. 
**** This tutorial is based on the one found in OpenCV’s tutorials, located here: http://docs.opencv.org/2.4/doc/tutorials/introduction/linux_install/linux_install.html
Steps 2-7 were taken directly from this tutorial. 
Before we begin installation, visit https://sourceforge.net/projects/opencvlibrary/?source=typ_redirect 
There you will find, under 'browse all files' and 'opencv-unix' the download link for the opencv folder. Please download version 2.4.13, as you will need to enter this folder in step 5 in order to complete the installation process. 

1. First, we need to ensure that all proper dependencies have been installed, please run ‘sudo apt-get update’ to make sure your machine is updated. 
2. ‘sudo apt-get install build-essential’ This will install the compiler
3. ‘sudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev’ These are required dependencies
4. ‘sudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev’ These are additional dependencies
5. If your downloaded opencv-2.4.13.zip was not unzipped, please unzip it and enter the folder: ‘cd ~/[your_opencv_folder]’ then make a temporary directory: ‘mkdir release’ and ‘cd release’
6. ‘cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local ..’
7. Within the directory ‘release’, enter the command ‘make’. When that is done running (it should take a while), enter ‘sudo make install’ to complete installation. 

Installing Keras with a Tensorflow Backend
1. First we will install Keras, which, assuming that pip3 is upgraded (you can run ‘pip3 install --upgrade pip’ to be sure), is as easy as ‘pip3 install keras’
2. When keras is finished installing, we will proceed to install the backend, Tensorflow, which does all of the heavy lifting that keras wraps into a nice package. 
3. Run ‘export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0-cp35-cp35m-linux_x86_64.whl’ to set TF_BINARY_URL to the version of tensorflow that you’d like (the url included here is the one that was used for this project)
4. Then, use ‘pip3 install --upgrade $TF_BINARY_URL’ to install Tensorflow
5. A dependency that this project uses is found in h5 files, and so run ‘pip3 install h5py’ to allow for their use and manipulation

Obtaining the Source Code
1. The source code is available at https://github.com/powerhouseofthecell/JPG2XML.git
2. And, before anything is run, give the software file permission to execute by entering ‘chmod +x img_to_xml.sh’

Installing music21 and pillow
1. This is as easy as ‘pip3 install music21 pillow’
2. music21 allows for writing to xml files, and pillow is image manipulation software

Finally, edit keras.json
1. This is the final step, due to settings shifts in the past and adjustments in the new version of keras, the order of shapes for input objects has changed. As a result, please use your favorite text editor (mine is nano) and type 'text_editor ~/.keras/keras.json' and from there, change the line reading 'image_dim_ordering' from 'tf' to 'th'. Exit and save. 

The software is now ready to run!

Running the software:
Note: This software was designed to convert jpeg (.jpg) images of sheet music into musicxml (.xml) file that can be read by software such as MuseScore or Finale. 

Defaults:
Note: when the script is run, you may get warnings about music21 needing optional dependencies, these can be safely ignored. You may also get warnings about an exit error involving 'TFStatus,' but these are the results of a bug involving Keras and Tensorflow and can be similarly safely ignored. 
1. To run with the default configurations (found in app/config.py), simply enter ‘./img_to_xml.sh filename.jpg’ (and hope for the best)
2. For your convenience, three example files are included with the software, and can be located by looking for files with the extension '.jpg'.

Changing template images:
1. The software comes pre-loaded with template images that work in many cases, but may not be compatible with your music score. In this case, it may be necessary to obtain your own templates in order for the computer vision software to locate clefs and notes in the image file.
2. If you want to attempt your own templates, there are two options for doing so:
a. You can add the template files that you are using to the templates folder (found in app/templates) and name your template for finding notes ‘t1.jpg’ and your template for finding clefs ‘t2.jpg’
b. OR you can edit the config.py file (found at app/config.py) and change the line defining ‘templates’. The first entry in the list is the file path for finding the note template, and the second is the file path for locating the clef template
3. Be aware that picking templates is a largely trial and error-based process, and so you may go through several custom templates before discovering one that works.
4. I found that I had the most luck with a template image of a note head and the center of a treble clef for most sheet music (that is within the limitations of this software, naturally)

Changing models:
1. This software uses machine learning algorithms to identify the pitches and lengths of notes that have been pulled from the input image, and if you would like to experiment with different models or different datasets, this software can easily output a new model. 
2. You can adjust dataset
       a. To change the data set used by either the length or pitch model, go to their respective directory in app/models/build/, and enter the data/ directory.
       b. Here is where you will find two directories, one for training, and one for validation
       c. Under each of those is a set of directories that constitutes the classes into which the software needs to learn to group input data. 
       d. In order to change the dataset used for training, enter these class directories and input new data that corresponds to the labels for the classes (the directory names). Ex. all ‘a’ note images should be placed in the directory labeled ‘a’
       e. Step d is the same for adjusting the validation data for the model
       f. Note: When the size of the datasets is adjusted, running the software may throw an insignificant warning about the fact that batch size and total sample size do not work out, but these can be adjusted in ‘x_classifier_maker.py’ located in the app/models/build/ directories
3. You can also adjust the model itself (this should only be done if you have made a backup of the original models, in case a change you make breaks the model) 
       a. The model files are located within app/models/build/ in their respective directories
       b. The ‘modelBuilder.py’ files in those directories build the actual model, layer by layer, and define how each layer is activated.                       Documentation for constructing the models can be found at https://keras.io
       c. Adjusting the ‘x_classifier_maker.py’ files in either directory allows for manipulation of batch size, which is the number of data files that are pulled at a given time for the algorithm to be taught on and intended image dimensions
4. Once your intended customizations/experimentations have been implemented, you can rebuild the model by entering either ‘python3 length_classifier_maker.py’ or ‘python3 pitch_classifier_maker.py’ in their respective directories. 
5. The output of running the model maker will be a new file in the respective app/models directory that houses the list of models to be used. This new file will be in the format type-minute-hour-day-month-year.h5
6. In order to use the new model in the software, please edit the config.py file located in app/ and adjust the file names listed under ‘pitch_model’ or ‘length_model’ accordingly

What to do with the output:
       This program is designed to output a .xml file of the same basename as the input .jpg file. This .xml file is readable by various programs, and importantly, can be used for musical manipulations: transposition, copy and paste, new parts, etc. 

