Design How:	The overall goal, in essence, was to take music files from .jpg format to .xml format. In order to accomplish this I followed this plan:1. Load the .jpg file, and analyze it using OpenCV2’s template matching functions to locate both the clefs in the image and the notes. 2. Once the notes and clefs were located, vertical boundaries for each clef were established, and notes were organized from left to right within these bounds, per clef. This means that the notes are in the same order that they would be read by a human musician. 3. These note sub-images are then saved to a temporary directory, from which they will be analyzed by the machine learning algorithms. 4. Before running this software, the machine learning models were built using samples of approximately 1000 images that were manually created (by me). 5. These models are then used to classify each of the images in the temporary directory twice. One classifies each note’s length, and the other classifies each note’s pitch. 6. Once the images have been classified, the software uses the music21 API to write the list of music notes from the temporary directory into a .xml formatted document. 7. The last step cleans up after the software has run, which involves asking if the user wants to keep the results.jpg file, and removing the temporary directory. Design Decisions and Why:Why two versions of python?	There is no truly satisfactory answer as to why I chose to use two versions of python in this project except that I was originally set on using the newest version, and I presumed that the most challenging aspect of this project would be the machine learning one. As a result, I installed and messed around with Keras and Tensorflow first, and these were easy enough to use in Python3. However, when it came time to use OpenCV 3, I discovered that the documentation on how to install it is inconsistent at best, and further documentation on use is difficult to procure. It was easier to understand, install, and implement OpenCV 2. The downside is, of course, that OpenCV 2 is compatible with Python 2.7 and not Python 3.5. Because I had already invested a significant amount of time in learning to use and setting up Keras and Tensorflow with Python 3, I decided to use both versions of Python and put them together using bash scripting at the end. Why Keras and Tensorflow?	When I was searching up tutorials on how to create machine learning algorithms, Keras popped up many times. I basically decided based on popularity that Keras would be the software for me. On top of that, it had nicely built documentation that I was sure would help me down the line. As for Tensorflow (as opposed to Theano), I chose to use TF because it is newer and is continuing to be updated with more features, past those found in Theano. Similar to how I decided to use Keras though, I took a rough poll of what was popular on the Internet forums and went with that option. What was the goal of this project?	Originally, my intent was to design a piece of software that could convert .jpg images of music (which are often easy to obtain, as a musician, on the Internet) to .xml files that a musician could manipulate in the software of their choice (these files are much harder to find for a given piece of music). I assumed at the start that the project would require me to limit the scope of what I did to identifying half, quarter, and eighth notes within the treble clef, as well as make a few other assumptions. Unfortunately, as I explored machine vision and learning, I discovered that as far as note lengths go, I would be most realistically limited to two kinds of notes (quarter and eighth). Further, I came to realize that identifying any more pitches than those found on the treble clef (without ledger lines) would be almost impossible in the given time frame. On top of that, my software makes no attempt to identify markings (staccato, tenuto, marcato), style, tempo, or other musical notations. In essence, my goal was boiled down to finding and correctly labeling 11 notes in one of two possible lengths over a whole sheet of music. Why not also identify and label “qualifiers” such as flat, sharp, and natural?	To be fair, I began with the intention of doing just that. However, I quickly discovered that because of the close proximity of eighth notes, setting the parameters for identifying the notes was almost impossible when they were large enough to incorporate “qualifiers.” What I mean by this is that there is a width parameter that decides how large of an image to capture in taking mini-snapshots of each note in the .jpg file. When this gets too large, eighth notes that are too close together get skipped. When it’s small enough to avoid skipping eighth notes, it instead is unable to pick up “qualifiers.”Why not train your machine algorithms on whole lines of music instead of doing it note-by-note?	While the line-by-line analysis was tempting, it is also incredibly data-intensive. In order to account for even a reasonable (and thus extrapolable) data set, more than 10000 lines would need to be captured and labeled. Additionally, these lines would not fit into a reasonable number of distinct classes, which means that they would be difficult for machine learning algorithms (at least to my knowledge) to process. My decision, then, was to break the music down into its fundamental components.Why did you not design a GUI for this software? Why is there no website?       In heeding the advice of my TF, I decided against spending precious time on a GUI because proving the concept of breaking down sheet music pictures and rebuilding them into .xml files was what this project was for. I recognize that a GUI or a web-interface may be useful, but both are relatively easy to construct around this software, which does all of the heavy lifting. I wanted to showcase my ability to delve into two new areas (for me at least), machine learning and computer vision, and I was prepared to spend more time working through that than I was tinkering with aesthetic elements. 

Why doesn’t your project work, really?
	Although my project compiles, and the software will pull everything together to take an image file and return a .xml file, it doesn’t work, at least not to any level of standard that I am near satisfied by. There are frequent, even drastic errors in the “transcription” that occurs in converting the image to the .xml file. However, I will offer a redemption to the project in that it can capture snippets of the music effectively, and I believe that it demonstrates the plausibility of the concept. I am unapologetic in the scope of the project that I attempted, and I am inspired to continue working to improve this as a method for facilitating the life of the musician transcriber/arranger who just wants to convert images of music into workable documents. 

In short, this project is the result of pulling together the work of a great deal of other people, and while this particular combination of everything is my own idea, I used the work of others extensively in understanding just how to make my own project come to life. Below are as many of the sources I used in this project that I could list, though CS50 lectures, problem sets, and teaching staff are also responsible for helping make this project exist. 

List of Sources Used in Understanding All of This:
Machine Learning:
http://machinelearningmastery.com/introduction-python-deep-learning-library-keras/
http://www.pyimagesearch.com/2016/11/14/installing-keras-with-tensorflow-backend/
http://www.pyimagesearch.com/2016/07/18/installing-keras-for-deep-learning/
https://keras.io
http://docs.opencv.org/2.4/doc/tutorials/introduction/linux_install/linux_install.html
https://keras.io/preprocessing/image/
https://keras.io/getting-started/faq/
https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html
http://stackoverflow.com/questions/29323592/how-to-create-and-format-an-image-dataset-from-scratch-for-machine-learning

Computer Vision:
https://sourceforge.net/projects/opencvlibrary/?source=typ_redirect
http://docs.opencv.org/2.4/doc/tutorials/imgproc/histograms/template_matching/template_matching.html

Misc.
http://pdf2jpg.net/convert.php#.WER8rHeZNE4
http://snipplr.com/view/7318/


